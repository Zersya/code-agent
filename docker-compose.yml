version: '3.8'

services:
  # PostgreSQL database with pgvector extension for vector embeddings
  postgres:
    image: pgvector/pgvector:pg16
    container_name: agent_reviewer_postgres
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-repopo_reviewer}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    restart: unless-stopped
    networks:
      - qodo_network
      - llm-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-repopo_reviewer}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  agent-reviewer-backend:
    build:
      context: ./agent-reviewer # Assuming Dockerfile for webhook-server is in the same directory as this docker-compose.yml
      dockerfile: Dockerfile # This refers to the Dockerfile in the Canvas
    container_name: agent_reviewer_backend
    environment:
      - PORT=${PORT:-9080}
      # Database connection to containerized PostgreSQL (internal port is always 5432)
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-repopo_reviewer}
      - GITLAB_API_TOKEN=${GITLAB_API_TOKEN}
      - GITLAB_API_URL=${GITLAB_API_URL}
      - GITLAB_USERNAME=${GITLAB_USERNAME}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
      - API_KEY=${API_KEY}
      - APP_URL=${APP_URL}
      - ADMIN_SECRET_KEY=${ADMIN_SECRET_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - QODO_EMBED_API_KEY=${QODO_EMBED_API_KEY}
      # Ensure this URL points to the service name and port of qodo-embed-api
      - QODO_EMBED_API_URL=${QODO_EMBED_API_URL}
      - LLM_PROVIDER=${LLM_PROVIDER}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_API_URL=${OPENROUTER_API_URL}
      - OPENROUTER_API_MODEL=${OPENROUTER_API_MODEL}
      - OLLAMA_API_URL=${OLLAMA_API_URL}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - ENABLE_MR_REVIEW=${ENABLE_MR_REVIEW}
      - ENABLE_PROJECT_CONTEXT=${ENABLE_PROJECT_CONTEXT}
      - WAIT_FOR_EMBEDDINGS=${WAIT_FOR_EMBEDDINGS}
      - EMBEDDING_WAIT_TIMEOUT=${EMBEDDING_WAIT_TIMEOUT}
      - AUTO_EMBED_PROJECTS=${AUTO_EMBED_PROJECTS}
      - TEMP_DIR=/app/temp
      - QUEUE_CONCURRENCY=${QUEUE_CONCURRENCY}
      - QUEUE_MAX_ATTEMPTS=${QUEUE_MAX_ATTEMPTS}
      - QUEUE_RETRY_DELAY=${QUEUE_RETRY_DELAY}
      - ENABLE_MIDNIGHT_SCHEDULING=${ENABLE_MIDNIGHT_SCHEDULING}
      - CIRCUIT_BREAKER_THRESHOLD=${CIRCUIT_BREAKER_THRESHOLD}
      - CIRCUIT_BREAKER_TIMEOUT=${CIRCUIT_BREAKER_TIMEOUT}
      - HEALTH_CHECK_CACHE_TTL=${HEALTH_CHECK_CACHE_TTL}
      - ENABLE_NOTION_INTEGRATION=${ENABLE_NOTION_INTEGRATION}
      - NOTION_API_TOKEN=${NOTION_API_TOKEN}
      - NOTION_API_TIMEOUT=${NOTION_API_TIMEOUT}
      - ENABLE_SEQUENTIAL_THINKING=${ENABLE_SEQUENTIAL_THINKING}
      - ENHANCED_CONTEXT_ENABLED=${ENHANCED_CONTEXT_ENABLED}
      - ENHANCED_CONTEXT_MAX_LINES=${ENHANCED_CONTEXT_MAX_LINES}
      - ENHANCED_CONTEXT_MAX_FILES=${ENHANCED_CONTEXT_MAX_FILES}
      - ENHANCED_CONTEXT_MAX_QUERIES=${ENHANCED_CONTEXT_MAX_QUERIES}
      - ENHANCED_CONTEXT_TIMEOUT_MS=${ENHANCED_CONTEXT_TIMEOUT_MS}
      - ENHANCED_CONTEXT_MAX_RESULTS_PER_QUERY=${ENHANCED_CONTEXT_MAX_RESULTS_PER_QUERY}
      - REVIEW_MODE=${REVIEW_MODE}
      - REVIEW_MAX_SUGGESTIONS=${REVIEW_MAX_SUGGESTIONS}
      - REVIEW_CONSERVATIVE_MODE=${REVIEW_CONSERVATIVE_MODE}
      - REVIEW_FOCUS_AREAS=${REVIEW_FOCUS_AREAS}
      - FOCUS_AREAS=${FOCUS_AREAS}
      - REVIEW_DOMAIN_SCOPE=${REVIEW_DOMAIN_SCOPE}
      - CRITICAL_ISSUE_THRESHOLD=${CRITICAL_ISSUE_THRESHOLD}
    volumes:
      - ./agent-reviewer/temp:/app/temp # Mounts a local ./temp directory to /app/temp in the container
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - qodo_network # Assigns this service to the qodo_network
      - llm-network # Assigns this service to the llm_network
      - proxy

  agent-reviewer-dashboard:
    build:
      context: ./agent-reviewer/frontend
      dockerfile: Dockerfile
    container_name: agent_reviewer_dashboard
    ports:
      - "${DASHBOARD_PORT:-9080}:80"
    depends_on:
      - agent-reviewer-backend
    restart: unless-stopped
    networks:
      - qodo_network
      - llm-network
      - proxy

  qodo-embed-api:
    # Assuming the Dockerfile for qodo-embed-api is in a subdirectory, e.g., ./qodo-embed-api-src
    # If it's in the same directory and named differently, adjust accordingly.
    # If it's also named Dockerfile but for a different service, it needs its own context.
    # For this example, let's assume its Dockerfile is in a directory named 'qodo_embed_api_service'
    build:
      context: ./qodo-embedding-service # Adjust this path to the directory containing the Dockerfile for qodo-embed-api
      dockerfile: Dockerfile # Or specify if it's named differently
    container_name: qodo_embed_api
    ports:
      - "4000:8000"
    restart: unless-stopped
    environment:
      - HF_HOME=/cache/huggingface
      - MODEL_NAME=Qodo/Qodo-Embed-1-1.5B
      - DEVICE=cuda
    volumes:
      - huggingface_cache_vol:/cache/huggingface
    networks:
      - qodo_network # Assigns this service to the qodo_network
      - llm-network # Assigns this service to the llm_network
      - proxy
    # --- Healthcheck (optional) ---
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # --- GPU Support (optional) ---
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

# Optional Ollama service (uncomment to use)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   restart: unless-stopped
  #   networks:
  #     - qodo_network
  #   # Uncomment to use GPU
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]

# Define the network that both services will share
networks:
  proxy:
    external: true
  llm-network:
    name: llm-network # Explicitly names the network
    driver: bridge    # Default driver
  qodo_network:
    name: qodo_network # Explicitly names the network
    driver: bridge    # Default driver

# Define the named volumes
volumes:
  postgres_data:
    driver: local
  huggingface_cache_vol:
    driver: local
  # ollama_data:
  #   driver: local
